{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "#code for creating the dataset\n",
    "\n",
    "j = 0\n",
    "\n",
    "text_detected_folder = '../../gdrive/MyDrive/text_detected_images'\n",
    "os.makedirs(text_detected_folder, exist_ok=True)\n",
    "\n",
    "yolo_dataset_folder = '../../gdrive/MyDrive/yolo_dataset'\n",
    "os.makedirs(yolo_dataset_folder, exist_ok=True)\n",
    "\n",
    "def extract_text(image):\n",
    "    return pytesseract.image_to_string(Image.fromarray(image))\n",
    "\n",
    "dataset_txt_path = os.path.join(yolo_dataset_folder, 'dataset.txt')\n",
    "\n",
    "def write_yolo_labels(txt_path, labels):\n",
    "    with open(txt_path, 'w') as txt_file:\n",
    "        for label in labels:\n",
    "            txt_file.write(label + '\\n')\n",
    "\n",
    "for line in json_lines:\n",
    "\n",
    "    data = json.loads(line)\n",
    "    \n",
    "    img_path = data[\"img\"]\n",
    "    print(img_path)\n",
    "\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    results = model.predict(source=img, save=False, save_txt=False)\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    person_detected = False\n",
    "\n",
    "    for i in range(len(results[0].boxes)):\n",
    "        box = results[0].boxes[i]\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf >= 0.5 and results[0].names[box.cls[0].item()] == \"person\":\n",
    "\n",
    "            print(\"persons: \", j)\n",
    "            j+=1\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            roi = img[y1:y2, x1:x2]\n",
    "\n",
    "            extracted_text = extract_text(roi)\n",
    "\n",
    "            if extracted_text:\n",
    "                person_detected = True\n",
    "                roi_filename = f\"{os.path.splitext(os.path.basename(img_path))[0]}.jpg\"\n",
    "                roi_path = os.path.join(text_detected_folder, roi_filename)\n",
    "                cv2.imwrite(roi_path, roi)\n",
    "                print(f\"Saved image with detected text: {roi_path}\")\n",
    "\n",
    "                img_height, img_width, _ = img.shape\n",
    "                x_center = ((x2 - x1) / 2 + x1) / img_width\n",
    "                y_center = ((y2 - y1) / 2 + y1) / img_height\n",
    "                width = (x2 - x1) / img_width\n",
    "                height = (y2 - y1) / img_height\n",
    "                labels.append(f\"0 {x_center} {y_center} {width} {height}\")  \n",
    "    if person_detected:\n",
    "        img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        img_labels_txt_path = os.path.join(yolo_dataset_folder, f'{img_name}.txt')\n",
    "        write_yolo_labels(img_labels_txt_path, labels)\n",
    "\n",
    "    if j == 1000:\n",
    "        break\n",
    "\n",
    "\n",
    "os.system(f\"cp {text_detected_folder}/*.jpg {yolo_dataset_folder}\")\n",
    "os.system(f\"cp {dataset_txt_path} {yolo_dataset_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data='data/dataset.yaml', epochs=10, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mhateful_memes\u001b[0m/  task1.ipynb  task3.ipynb  yolov8n.pt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_model.train(data='coco8.yaml', epochs=20, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "\n",
    "with open('train.jsonl', 'r') as f:\n",
    "    json_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytesseract in /home/aadi/.local/lib/python3.10/site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/lib/python3/dist-packages (from pytesseract) (9.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from pytesseract) (21.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aadi/precog/hateful_memes\n"
     ]
    }
   ],
   "source": [
    "cd hateful_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "j = 0\n",
    "\n",
    "for line in json_lines:\n",
    "    data = json.loads(line)\n",
    "    img_path = data[\"img\"]\n",
    "    \n",
    "    print(img_path)\n",
    "    \n",
    "    result_test = test_model.predict(source=img, save=False, save_txt=False)\n",
    "    result_predict = model.predict(source=img, save=False, save_txt=False)\n",
    "\n",
    "    if result_test and result_predict:  # Check if both are not empty\n",
    "        for i in range(min(len(result_test[0].boxes), len(result_predict[0].boxes))):\n",
    "            box_t = result_test[0].boxes[i]\n",
    "            box_p = result_predict[0].boxes[i]\n",
    "            \n",
    "            if box_t and box_p:\n",
    "                conf_t = round(box_t.conf[0].item(), 2)\n",
    "                conf_p = round(box_p.conf[0].item(), 2)\n",
    "\n",
    "                if result_test[0].names[box_t.cls[0].item()] == \"person\":\n",
    "                    print(\"Model trained on an actual dataset: \", conf_t)\n",
    "                    print(\"Model trained on custom dataset: \", conf_p)\n",
    "\n",
    "                    \n",
    "            \n",
    "    j += 1\n",
    "    if j == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'hateful_memes/img/01245.png'\n",
    "keras_ocr.tools.read(img)\n",
    "pred = pipeline.recognize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mhateful_memes\u001b[0m/  task1.ipynb  task2.ipynb  task3.ipynb  yolov8n.pt\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(img)\n",
    "annotated_image = image.copy()\n",
    "\n",
    "for box in pred[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1]\n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3]\n",
    "\n",
    "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# Display the annotated image\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#can use inpaint from cv2 to cover image by creating a mask over the text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
